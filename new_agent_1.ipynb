{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spark_env.env import Environment\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import dgl\n",
    "import torch\n",
    "from spark_env.job_dag import JobDAG\n",
    "from spark_env.node import Node\n",
    "import torch.nn as nn\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "\n",
    "    def __init__(self, features=5, hidden_layer_size=10, embedding_size=10, layers=3):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv = []\n",
    "        self.layers = layers\n",
    "        self.conv.append(GraphConv(features, hidden_layer_size))\n",
    "        for i in range(layers-2):\n",
    "            self.conv.append(GraphConv(hidden_layer_size, hidden_layer_size))\n",
    "        self.conv.append(GraphConv(hidden_layer_size, embedding_size))\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = inputs\n",
    "        for i in range(self.layers):\n",
    "            h = self.conv[i](g, h)\n",
    "            if i != self.layers-1:\n",
    "                h = torch.relu(h)\n",
    "        return h\n",
    "\n",
    "def translate_state(obs, node_input_dim=5, job_input_dim=3):\n",
    "        \"\"\"\n",
    "        Translate the observation to matrix form\n",
    "        \"\"\"\n",
    "        job_dags, source_job, num_source_exec, frontier_nodes, executor_limits, \\\n",
    "        exec_commit, moving_executors, action_map = obs\n",
    "\n",
    "        # compute total number of nodes\n",
    "        total_num_nodes = int(np.sum([job_dag.num_nodes for job_dag in job_dags]))\n",
    "\n",
    "        # job and node inputs to feed\n",
    "        node_inputs = np.zeros([total_num_nodes, node_input_dim])\n",
    "        job_inputs = np.zeros([len(job_dags), job_input_dim])\n",
    "\n",
    "        # sort out the exec_map\n",
    "        exec_map = {}\n",
    "        for job_dag in job_dags:\n",
    "            exec_map[job_dag] = len(job_dag.executors)\n",
    "        # count in moving executors\n",
    "        for node in moving_executors.moving_executors.values():\n",
    "            exec_map[node.job_dag] += 1\n",
    "        # count in executor commit\n",
    "        for s in exec_commit.commit:\n",
    "            if isinstance(s, JobDAG):\n",
    "                j = s\n",
    "            elif isinstance(s, Node):\n",
    "                j = s.job_dag\n",
    "            elif s is None:\n",
    "                j = None\n",
    "            else:\n",
    "                print('source', s, 'unknown')\n",
    "                exit(1)\n",
    "            for n in exec_commit.commit[s]:\n",
    "                if n is not None and n.job_dag != j:\n",
    "                    exec_map[n.job_dag] += exec_commit.commit[s][n]\n",
    "\n",
    "        # gather job level inputs\n",
    "        job_idx = 0\n",
    "        for job_dag in job_dags:\n",
    "            # number of executors in the job\n",
    "            job_inputs[job_idx, 0] = exec_map[job_dag] / 20.0\n",
    "            # the current executor belongs to this job or not\n",
    "            if job_dag is source_job:\n",
    "                job_inputs[job_idx, 1] = 2\n",
    "            else:\n",
    "                job_inputs[job_idx, 1] = -2\n",
    "            # number of source executors\n",
    "            job_inputs[job_idx, 2] = num_source_exec / 20.0\n",
    "\n",
    "            job_idx += 1\n",
    "\n",
    "        # gather node level inputs\n",
    "        node_idx = 0\n",
    "        job_idx = 0\n",
    "        for job_dag in job_dags:\n",
    "            for node in job_dag.nodes:\n",
    "\n",
    "                # copy the feature from job_input first\n",
    "                node_inputs[node_idx, :3] = job_inputs[job_idx, :3]\n",
    "\n",
    "                # work on the node\n",
    "                node_inputs[node_idx, 3] = \\\n",
    "                    (node.num_tasks - node.next_task_idx) * \\\n",
    "                    node.tasks[-1].duration / 100000.0\n",
    "\n",
    "                # number of tasks left\n",
    "                node_inputs[node_idx, 4] = \\\n",
    "                    (node.num_tasks - node.next_task_idx) / 200.0\n",
    "\n",
    "                node_idx += 1\n",
    "\n",
    "            job_idx += 1\n",
    "\n",
    "        return node_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment()\n",
    "done = False\n",
    "reset_prob = 5e-7\n",
    "env.seed(234)\n",
    "env.reset(max_time=np.random.geometric(reset_prob))\n",
    "\n",
    "job_graph, frontier_nodes, executor_limits, exec_graph, action_map = env.new_observation()\n",
    "node_inputs = translate_state(env.observe())\n",
    "\n",
    "job_graph_set = dgl.from_networkx(job_graph)\n",
    "node_inputs = torch.tensor(node_inputs)\n",
    "# nx.draw(job_graph, with_labels=True)\n",
    "# plt.show()\n",
    "\n",
    "net = GCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = dgl.add_self_loop(job_graph_set)\n",
    "inputs = node_inputs.type(torch.FloatTensor)\n",
    "logits = net(G, inputs)\n",
    "required_indices = []\n",
    "e_graph = nx.DiGraph()\n",
    "\n",
    "for node in frontier_nodes:\n",
    "    e_graph.add_node(action_map.inverse_map[node])\n",
    "    required_indices.append(action_map.inverse_map[node])\n",
    "\n",
    "last_node = 10000\n",
    "e_graph.add_node(last_node)\n",
    "\n",
    "for node in frontier_nodes:\n",
    "    e_graph.add_edge(action_map.inverse_map[node], last_node)\n",
    "\n",
    "e_input = logits[required_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs = env.observe()\n",
    "# job_dags, source_job, num_source_exec, frontier_nodes, executor_limits, exec_commit, moving_executors, action_map = obs\n",
    "# total_reward = 0\n",
    "# loops = 0\n",
    "\n",
    "# dag_list = []\n",
    "# dag_map = {}\n",
    "\n",
    "# while not done:\n",
    "    \n",
    "#     eq = np.random.randint(1, 5)\n",
    "#     eq = min(eq, num_source_exec)\n",
    "\n",
    "#     if(len(frontier_nodes)) == 0:\n",
    "#         break\n",
    "\n",
    "#     for node in frontier_nodes:\n",
    "\n",
    "#         if len(dag_list) == 0:\n",
    "#             dag_map[node.job_dag] = True\n",
    "#             dag_list.append((node, action_map.inverse_map[node]))\n",
    "#         elif node.job_dag in dag_map:\n",
    "#             dag_list.append((node, action_map.inverse_map[node]))\n",
    "\n",
    "#         obs, reward, done = env.step(node, eq)\n",
    "#         break\n",
    "\n",
    "#     total_reward += reward\n",
    "#     if not done:\n",
    "#         job_dags, source_job, num_source_exec, frontier_nodes, executor_limits, exec_commit, moving_executors, action_map = obs\n",
    "#         print(moving_executors)\n",
    "#     input()\n",
    "\n",
    "# print(total_reward)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pylab\n",
    "\n",
    "# def save_graph(graph, file_name):\n",
    "#     plt.figure(num=None, figsize=(20, 20), dpi=80)\n",
    "#     plt.axis('off')\n",
    "#     fig = plt.figure(1)\n",
    "#     pos = nx.spring_layout(graph)\n",
    "#     nx.draw_networkx_nodes(graph,pos)\n",
    "#     nx.draw_networkx_edges(graph,pos)\n",
    "#     nx.draw_networkx_labels(graph,pos)\n",
    "\n",
    "#     plt.savefig(file_name,bbox_inches=\"tight\")\n",
    "#     pylab.close()\n",
    "#     del fig\n",
    "\n",
    "# save_graph(job_graph, \"job_dag\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}